Legened:
(F) -> factors very important metrics
[L] -> level range of values of factors

General remarks:
- does I/O makes sense -> assumption data fits into memory (not to mention disk)? <- replace by transmission time from data node to computation node (includes mapping)

Evaluation technique -> measurement

Assumption list (for clouds up to 100 computation nodes):
- network bandwidth delays/packet losses can be ignored (small fraction)
- node failures(rollbacks) and speculative nodes(speculative execution) can be ignored (small fraction)

Assumption list (for clouds with more than 100 computation nodes):
- node partition fits memory/disk

Metrics:
- turnaround time (totalTime);
// The time between submission of a request and the beginning of its execution by the system is
// called the reaction time.
- reaction time
// The ratio of response time (turnaround time) at a particular load to that at the minimum load.
- stretch factor
// the rate (requests per unit of time) at which the requests can be serviced by the system
- Throughput (jobs per minute || minutes per job) <- one of these
- computationTime;
- initTransmissionTime
- computationTransmissionTime;
- totalTransmissionTime
- ioTime;
- partitioningTime -> (random vs smart)
- idleTime
- transmissionDataSize;
- partitionDataSize;
- speculative execution time -> computation time of the speculative node for a certain task (as overhead to std computation time)
- master swap time -> time to perform master swap and rollback IF master fails
// The utilization gives an indication of the percentage of time the resources of the gateway are busy
// for the given load level. The resource with the highest utilization is called the bottleneck.
- utilization (find bottleneck)
    1. transmission
    2. computation
    3. I/O

Performance parameters list:
    System parameters:
        (F[10, 100, >100])computationalNodes# -> resources available
        network bandwidth -> transmission speed
        computationalNodeMemorySize -> max data size to be processed avoiding disk I/O
        computationalNodeDiskSize -> max data size to be processed
        (F[random, smart])"random"/"cluster" partitioning -> #transmissions and size between computational nodes
        (F[long delay, acceptable delay, immediate])all requested resources granted on time -> fully use of resources
        nodes failures and rollbacks -> slowing down the total computation time
        #speculativeNodes -> use two nodes for computation instead of one (speculative execution)
        (F[cpuIntensive, diskIntensive, transmissionIntensive])algorithm type -> overall speed of execution
    Workload parameters:
        (F[1000, 10000, 100000, 1000000, n])edgeSize -> problem size
        (F[1000, 10000, 100000, 1000000, n])nodeSize -> problem size
        (F[<10, <100, <1000, fullyConnected])avgNodeDegree -> computation more edges per node longer computation per node
        distance (diameter property) -> problem size
        reach (sna) -> computation time + ghostRows = minimize #transmissions